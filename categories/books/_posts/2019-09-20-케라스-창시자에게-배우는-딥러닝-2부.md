---
layout: post
title: 케라스 창시자에게 배우는 딥러닝 -2부-
description: >
  케라스 창시자에게 배우는 딥러닝 -2부-
excerpt_separator: <!--more-->
---

<!--more-->

# 2019-09-18-케라스 창시자에게 배우는 딥러닝 -2부-

2019.09.20 시작 ~ 2019.09.23 끝

## &#128214; 2부

### &#128218; 5장. 컴퓨터 비전을 위한 딥러닝

#### 5-1. CNN

1. MNIST 데이터를 사용한 심플한 예제

   ```python
   #########
   # model.py
   from keras import layers
   from keras import models
   
   model = models.Sequential()
   model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
   model.add(layers.MaxPooling2D((2, 2)))
   model.add(layers.Conv2D(64, (3, 3), activation='relu'))
   model.add(layers.MaxPooling2D((2, 2)))
   model.add(layers.Conv2D(64, (3, 3), activation='relu'))
   
   # 분류기
   model.add(layers.Flatten())
   model.add(layers.Dense(64, activation='relu'))
   model.add(layers.Dense(10, activation='softmax'))
   ```

   ```python
   ##########
   # train.py
   from keras.datasets import mnist
   from keras.utils import to_categorical
   import model
   
   (train_images, train_labels), (test_images, test_labels) = mnist.load_data()
   train_images = train_images.reshape((60000, 28, 28, 1))
   train_images = train_imaes.astype('float32') / 255
   
   test_images = test_imges.reshape((10000, 28, 28, 1))
   test_images = test_iamges.astype('float32') / 255
   
   train_labels = to_categorical(train_lbaels)
   test_labels = to_categorical(test_labels)
   
   model.compile(optimizer='rmsprop',
                 loss='categorical_crossentropy',
                 metrics=['accuracy'])
   model.fit(train_images, train_labels, epochs=5, batch_size=64)
   ```

   - ConvNet은 (image_height, image_width, image_channels) 크기의 입력 텐서를 사용한다.
   - 높이와 너비 차원은 네트워크가 깊어질수록 작아지는 경향이 있다.
   - Dense 층에 넣기 위해서는 3D 출력은 1D 텐서로 펼쳐야 한다.

2. 합성곱 연산

   - Dense 층은 입력의 전역 패턴을 학습
   - Conv 층은 지역 패턴을 학습 (이미지는 에지(edge), 질감(texture) 등 지역 패턴으로 분해될 수 있기 때문)

   이러한 특징 때문에 ConvNet는 다음과 같은 성질이 있다.

   - 학습된 패턴은 평행 이동 불변성(translation invariant)을 가진다. 패턴을 학습하면 위치는 상관이 없다. 이로인해 적은 수의 훈렴 샘플을 사용해서 일반화 능력을 가질 수 있도록 학습 가능
   - 패턴의 공간적 계층 구조를 학습할 수 있다. 작은 지역 패턴부터 큰 영역 패턴까지. 그 이유는 층을 통과하면서 크기가 작아지는 반면, 윈도우 사이즈는 그대로이기 때문에 더 넓은 영역에서 패턴을 찾게 된다.

3. 패딩 (padding)

   5x5 특성 맵에서 3x3 윈도우로 합성곱을 할 수 있는 부분은 3x3 크기를 가진다.
   따라서 입력으로 들어온 크기보다 결과가 작아지게 된다.

   입력과 동일한 크기를 가진 출력은 얻기 위해서 패딩을 사용한다. 패딩은 입력 특성 맵의 가장자리에 윈도우크기 $$W_{size}$$ /2 만큼 행,열을 0으로 추가한다.

   > keras에서 Conv2D에 padding="valid | same"

   

4. 스트라이드 (stride)

   출력 크기에 영향을 미치는 한 가지 요소. Conv는 윈도우가 모든 영역을 움직이면서 훑는 것. 이 때 두 번의 연속적인 윈도우 사이의 거리를 스트라이드라는 파라미터로 설정 가능.

5. 최대 풀링 연산

   MaxPooling2D는 강제적으로 특성 맵을 Down Sampling하는 것.
   최대 풀링은 윈도우에 맞는 패치(patch)를 추출하고 각 채널별로 최댓값을 출력.

   최대 풀링은 사용하는 이유는

   - 처리할 특성 맵의 가중치 개수를 줄이기 위해
   - Conv 층에 사용되는 윈도우가 더 넓은 영역을 커버할 수 있도록

#### 5-2. 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련하기

문제를 해결하기 위해 수집한 데이터의 수가 적을 경우는 매우 많다.
그리고 그 데이터를 훈련, 테스트, 검증 세 분류로 나눠서 사용해야 한다.

데이터 수에 관련된 문제를 해결하기 위해서 5-2절에서는 <b>데이터 증식(data augmentation)</b>을 사용한다.

1. 작은 데이터셋 문제에서 딥러닝의 타당성

   딥러닝의 근본적인 특징은 훈련 데이터에서 특성 공학의 수작업 없이 흥미로운 특성을 찾을 수 있다는 것이고, 이는 훈련 샘플이 많아야 가능하다. 특히 이미지처럼 매우 고차원인 문제에서는 특히 그렇다.

   하지만 훈련 샘플이 많다는 것은 네트워크의 크기와 깊이에 상대적이다. ConvNet은 지역적이고 평행 이동으로 변하지 않는 특성을 학습하기 때문에 지각에 관한 문제에서 매우 효율적으로 데이터를 사용한다. 따라서 모델이 작고 규제가 잘 되어 있다면 충분히 성능을 낼 수 있다.

   그리고 딥러닝 모델은 매우 다목적이다. 다른 모델을 조금만 변경해서 다른 문제에 재사용할 수 있고, 특히 컴퓨터 비전에서는 ImageNet 데이터로 사전 훈련된 모델들이 존재해서 매우 적은 데이터에서 강력한 비전 모델을 만드는데 사용할 수 있다.

2. 이미지 전처리

   keras.preprocessing.image의 ImageDataGenerator을 이용해서 픽셀 값을 0~1로 조정하고, flow_from_directory() 메소드를 이용해서 해당 디렉토리로 부터 데이터를 가져온다.

   ```python
   from keras.preprocessing.image import ImageDataGenerator
   
   train_datagen = ImageDataGenerator(rescale=1./255)
   test_datagen = ImageDataGenerator(rescale=1./255)
   
   train_generator = train_datagen.flow_from_directory(
   		train_dir,		# 사전에 경로 설정
   		target_size=(150, 150),
   		batch_size=20,
   		class_mode='binary')
   
   validation_generator = test_datagen.flow_from_directory(
   		validation_dir,  # 사전에 경로 설정
   		target_size=(150, 150),
   		batch_size=20,
   		class_mode='binary')  # 다중 분류 : categorical, sparse, 이진 분류 : binary
                                  # categorical은 원-핫 인코딩된 2차원 배열 반환
                                  # sparse는 정수 레이블을 담은 1차원 배열 반환
   ```

3. 모델 훈련

   ```python
   history = model.fit_generator(train_generator,
                                 steps_per_epoch=100,
                                 epochs=30,
                                 validation_data=validation_generator,
                                 validation_steps=50)
   model.save('model.h5')
   ```

4. 시각화

   ```python
   import matplotlib.pyplot as plt
   
   acc = history.history['acc']
   val_acc = history.history['val_acc']
   loss = history.history['loss']
   val_loss = history.history['val_loss']
   
   epochs = range(1, len(acc) + 1)
   
   plt.plot(epochs, acc, 'bo', label='Training acc')
   plt.plot(epochs, val_acc, 'b', label='Validation acc')
   plt.title('Training and validation accuracy')
   plt.legend()
   
   plt.figure()
   
   plt.plot(epochs, loss, 'bo', label='Training loss')
   plt.plot(epochs, val_loss, 'b', label='Validation loss')
   plt.title('Training and validation loss')
   plt.legend()
   
   plt.figure()
   ```

5. data augmentation

   데이터에 랜덤한 변환을 적용하여 샘플을 늘리는 기법.

   ```python
   datagen = ImageDataGenerator(rotation_range=20,			# 회전
                                width_shift_range=0.1,		# 평행 이동
                                height_shift_range=0.1,	
                                shear_range=0.1,			# shearing transformation
                                zoom_range=0.1,			# 확대
                                horizontal_flip=True,		# 수평 전환
                                fill_mode='nearest')		# 회전이나 가로/세로 이동으로 인해
                                                            # 새롭게 생성해야할 픽셀 채울 전략
                                                            # nearest, constant, reflect, wrap
   ```

6. regularization

   Dropout을 Dense 층 앞에 추가하면 더 성능이 좋아질 가능성이 있음. Overfitting 방지.

#### 5-3. 사전 훈련된 ConvNet 사용

pretrained network를 사용하는 두 가지 방법. <b>특성 추출(feature extraction), 미세 조정(fine tuneing)</b>

1. 특성 추출

   사전 학습된 네트워크의 표현을 사용해서 새로운 샘플에서 특성을 뽑아내는 것. 이런 특성을 사용해서 새로운 분류기를 처음부터 훈련한다. 즉, 사전 학습된 네트워크의 Conv 층만 재사용한다.

   특정 Conv 층에서 추출한 표현의 일반성과 재사용성 수준은 층의 깊이에 따라 다르다. 모델의 하위 층은 (에지, 색, 질감 등) 지역적이고 매우 일반적인 특성 맵을 추출하고, 상위 층은 ('강아지 눈'이나 '고양이 귀' 등) 추상적인 개념을 추출한다. 따라서 새로운 데이터셋이 원본 모델이 훈련한 데이터셋과 많이 다르다면 모델의 하위 층 몇개만 특성 추출에 재사용하는 것이 좋다.

   keras.applications 모듈에서 임포트 할 수 있는 이미지 분류 모델

   - Xception		: "Xception: Deep Learning with Depthwise Separable Convolutions," arXiv (2016)
   - Inception V3  : "Rethinking the Inception Architecture for Computer Vision," arXiv (2015)
   - ResNet50      : "Deep Residual Learning for Image Recognition," arXiv (2015)
   - VGG16          : "Very Deep Convolutional Network for Large-Scale Image Recognition," arXiv (2014)
   - MobileNet      : "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications," arXiv (2017)
   - DenseNet      : "Densely Connected Convolutional Networks," arXiv (2016)
   - NASNet         : "Learning Transferable Architectures for Scalable Image Recognition," arXiv (2017)

   ```python
   from keras.applications import VGG16
   
   conv_base = VGG16(weights='imagenet',
                     include_top=False,
                     input_shape=(150, 150, 3))
   ```

   위의 코드에서 weights는 모델을 초기화할 가중치 체크포인트(checkpoint)를 지정. include_top은 네트워크의 최상위 완전 연결 분류기 포함 여부를 결정.

   사전 학습 모델을 이용해서 새로운 모델을 학습시키는 방법은 두 가지가 있다.

   1. 비용이 적은 방법 : 기존 모델에 새로운 데이터셋을 입력으로 실행해서 나온 출력은 NumPy 배열로 저장. 그 다음 독립된 분류기에 입력으로 넣어 학습. 이 방법은 전체 과정에서 가장 비용이 많이 드는 Conv 연산이 모든 입력 이미지에 대해 한 번만 실행하면 되므로 빠르고 비용이 적다. 하지만 data augmentation을 사용할 수 없다.

   2. end-to-end 방법 : 준비한 모델위에 새로운 분류기를 쌓아서 학습. 비용이 많이 든다.

      ```python
      from keras import models
      from keras import layers
      
      model = models.Sequential()
      mode.add(conv_base)
      model.add(layers.Flatten())
      model.add(layers.Dense(256, activation='relu'))
      model.add(layers.Dense(1, activation='sigmoid'))
      ```

      이 방법을 사용할 때 가장 중요한 것은 모델을 컴파일하고 훈련하기 전에 Conv_base를 동결하는 것이다. 층을 동결한다는 것은 훈련하는 동안 가중치가 업데이트되지 않도록 막는다는 뜻이며, 사전에 학습된 표현이 수정되지 않도록 하는 방법이다.

      keras에서는 trainable 속성을 False로 설정하면 된다.

      ```python
      conv_base.trainable = False
      ```

2. 미세 조정 (fine tuning)

   특성 추출에 사용했던 동결 모델의 상위 층 몇개를 동결에서 해제하고 모델에 새로 추가한 층과 함께 훈련하는 것.
   주어진 문제에 조금 더 밀접하게 재사용 모델의 표현을 일부 조정하기 때문에 미세 조정이라고 함.

   이 때 분류기를 미리 훈련하지 않으면 너무 큰 오차 신호가 전파되어 사전에 학습한 표현들이 망가질 수 있다. 그래서 학습 방법은 다음과 같다.

   - 사전에 훈련된 기반 네트워크 위에 새로운 네트워크를 추가
   - 기반 네트워크를 동결
   - 새로 추가한 네트워크 훈련
   - 기반 네트워크에서 일부 층의 동결을 해제
   - 동결을 해제한 층과 새로 추가한 층을 함께 훈련

   ```python
   conv_base.summary() # summary 메소드를 통해 기본 모델의 구성 layer을 확인할 수 있음.
   
   conv_base.trainable = True
   
   set_trainable = False
   for layer in conv_base.layers:
       if layer.name == 'block5_conv1':
           set_trainable = True
           
       if set_trainable:
           layer.trainable = True
       else:
           layer.trainable = False
   ```

> <b>Q. 손실이 감소되지 않았는데 어떻게 정확도가 안정되거나 향상될 수 있을까?</b>
>
> 손실은 평균이다. 하지만 정확도에 영향을 미치는 것은 손실 값의 분포이지 평균이 아니다. 정확도는 모델이 예측한 클래스 확률이 어떤 임계 값을 넘었는지에 대한 결과이다. 따라서 모델이 더 향상되더라도 평균 손실에 반영되지 않을 수 있다.

#### 5-4. ConvNet 학습 시각화

- ConvNet 중간층의 출력
- ConvNet 필터를 시각화
- 클래스 활성화에 대한 히트맵을 이미지에 시각화

관련 정리한 내용은 <a href="../../study/_posts/2019-09-20-MACHINE_LEARNING-ConvNet-학습-시각화.md">MACHINE_LEARNING - ConvNet 학습 시각화</a>에서 참고.

### &#128218; 6장. 텍스트와 시퀀스를 위한 딥러닝

#### 6-1. 텍스트 데이터 다루기

텍스트는 가장 흔한 시퀀스 형태의 데이터. 시퀀스 데이터를 처리하는 기본적인 딥러닝 모델은 <b>순환 신경망(recurrent neural network)과 1D 컨브넷(1D convnet)</b>.

모델을 학습시킬 때 텍스트 원본을 입력으로 사용하지 못함. 딥러닝 모델은 수치형 텐서만 다룰 수 있기 때문. 텍스트를 수치형 텐서로 변환하는 과정을 <b>텍스트 벡터화(vectorizing)</b>라고 함. 다양한 방법이 존재.

- 텍스트를 단어로 나누고 각 단어를 하나의 벡터로 변환
- 텍스트를 문자로 나누고 각 문자를 하나의 벡터로 변환
- 텍스트에서 단어나 문자의 n-그램(n-gram)을 추출하여 각 n-그램을 하나의 벡터로 변환. n-그램은 연속된 단어나 문자의 그룹으로 텍스트에서 단어나 문자를 하나씩 이동하면서 추출.

텍스트를 나누는 단위(단어, 문자, n-그램)을 <b>토큰(token)</b>이라고 함. 토큰으로 나누는 작업은 토큰화(tokenization)
토큰과 벡터를 연결하는 방법은 여러가지가 있는데, 주요 두 가지 방법은 <b>원-핫 인코딩(one-hot encoding)과 토큰 임베딩(token embedding) 혹은 단어 임베딩(word embedding)</b>이다.

> <b>n-그램과 BoW</b>
>
> 단어 n-그램은 문장에서 추출한 N개(또는 그 이하)의 연속된 단어 그룹이다. 단어 대신 문자에도 적용 가능.
> 만약 "The cat sat on the mat."이란 문장이 있을 때 2-그램의 집합으로 분해한다면 다음과 같다.
>
> <p align="center">{"The", "The cat", "cat", "cat sat", "sat", "sat on", "on", "on the", "the", "the mat", "mat"}</p>
>또 다음 3-그램의 집합으로 분해한다면 다음과 같다.
> 
><p align="center">{"The", "The cat", "cat", "cat sat", "The cat sat", "sat", "sat on", "on", "cat sat on", "on the", "the", "sat on the", "the mat", "mat", "on the mat"}</p>
> 이런 집합을 각각 bag of 2-gram, bag of 3-gram이라고 한다. 이런 종류의 토큰화 방법을 BoW(Bag-of-Words).
>
> BoW는 순서가 없는 토큰화 방법이기 때문에 얕은 학습 방법의 언어 처리 모델에 사용되는 경향이 있음. 일종의 특성 공학.

##### 단어 임베딩 (word embedding)

단어 임베딩은 밀집 단어 벡터를 사용하는 것. 원-핫 인코딩으로 만든 벡터는 sparse하고 고차원이지만, 단어 임베딩은 저차원의 실수형 밀집 벡터이다. 원-핫 인코딩으로 얻은 단어 벡터와 달리 단어 임베딩은 데이터로부터 학습된다. 보통 256차원, 512차원 또는 큰 어휘 사전을 다룰 때는 1,024차원이 단어 임베딩을 사용한다.

만드는 방법은 두 가지이다.

- 관심 대상인 문제와 함께 단어 임베딩을 학습. 랜덤한 단어 벡터로 시작해서 가중치 학습.
- 다른 머신러닝에서 미리 계산된 단어 임베딩을 로드. pretrained word embedding

단어 벡터 간에 추상적인 관계를 얻으려면 단어 사이에 있는 의미 관계를 반영해야 한다. 단어 임베딩은 언어를 기하학적 공간에 매핑하는 것이다. 예를 들어 잘 구축된 임베딩 곤간에서는 동의어가 비슷한 단어 벡터로 임베딩 된다. 또한 벡터로 표현할 수 있기 때문에, 어떤 특성을 빼거나 더해서 다른 벡터로 연결할 수도 있다.

```python
from keras.layers import Embedding

# Embedding 층은 가능한 토큰의 개수와 임베딩차원 이렇게 2개의 매개변수를 받는다.
# (samples, sequence_length, embedding_dimensionality)인 3D 실수형 텐서 반환.
embedding_layer = Embedding(1000, 64)
```

단어 임베딩을 구하는 여러가지 기법

- <a href="https://code.google.com/archive/p/word2vec">Word2vec</a>

- <a href="https://nlp.stanford.edu/projects/glove">GloVe(Global Vectors for Word Representation)</a> : 단어의 동시 출현(co-occurrence) 통계를 기록한 행렬을 분해하는 기법 사용.

  > <b>co-occurrence</b>
  >
  > 언어학에서 형태소나 음소가 올바른 문법의 문장 안에 동시에 나타나는 것.

##### 데이터 토큰화

```python
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
import numpy as np

maxlen = 100
training_samples = 200
validation_samples = 10000
max_words = 10000 # 빈도 높은 1만개 단어만 사용

tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(texts)
sequences = tokenizer.texts_to_sequences(texts)

word_index = tokenizer.word_index
data = pad_sequences(sequences, maxlen=maxlen)
```

#### 6-2. 순환 신경망 이해하기

글을 이용해 문제를 풀기 위해서는 입력이 개별적으로 처리되지 않고 연속성을 유지할 수 있는, 즉 상태가 유지되는 네트워크가 필요하다. <b>순환 신경망(Recurrent Neural Network, RNN)</b>이 이러한 문제를 해결하는데 사용되는 가장 기본적인 모델이다. 이 모델은 시퀀스의 원소를 순회하면서 지금까지 처리한 정보를 상태(state)에 저장한다. 다시 말해 한 개의 데이터 포인트가 한 번에 처리되지 않고, 시퀀스의 원소를 차례대로 돌면서 처리한다.

![RNNflow](https://user-images.githubusercontent.com/27988544/65310453-4e4ba300-dbc9-11e9-92e4-00af54e04d85.jpg)

<p align="center">RNN model</p>
- RNN은 (timesteps, input_features)인 2D 텐서로 인코딩된 벡터의 시퀀스를 입력으로 사용.
- 시퀀스는 타임스텝을 따라서 반복.
- 각 타임스텝 t에서 현재 상태와 (input_features,) 크기의 입력을 연결하여 출력을 계산.
- 그리고 이 출력을 다음 스텝의 상태로 설정.
- 첫 번째 타임스텝에서는 이전 출력이 정의되지 않으므로 초기 상태(initial state)인 0 벡터로 초기화.

```python
##########
# numpy로 RNN 구현
import numpy as np

timesteps = 100
input_features = 32
output_features = 64

# 입력 데이터
inputs = np.random.random((timesteps, input_features))

# 초기 상태: 모두 0인 벡터
state_t = np.zeros((output_features, ))

# 가중치
W = np.random.random((output_features, input_features))
U = np.random.random((output_features, output_features))
b = np.random.random((output_faetures, ))

successive_outputs = []
for input_t in inputs:
    # 입력과 현재 상태(이전 출력)를 연결해서 현재 출력을 얻는다.
    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)
    successive_outputs.append(output_t)
    state_t = output_t

# 최종 출력 : (timesteps, output_features)
final_output_sequence = np.stack(successive_outputs, axis=0)
```

출력 텐서은 각 타임스텝 0에서 t까지 전체 과거에 대한 정보를 담고 있다. 우리는 전체 시퀀스에 대한 정보가 필요하기 때문에 마지막 출력만 사용한다.

##### 케라스의 순환 층

위에서 넘파이로 구현한 내용이 케라스의 SimpleRNN 층에 해당한다.

```python
from keras.layers import SimpleRNN
```

SimpleRNN이 한 가지 다른 점은 넘파이 예제처럼 하나의 시퀀스가 아니라 다른 케라스 층과 마찬가지로 시퀀스 배치를 처리한다는 것. 즉, (batch_size, timesteps, input_features) 크기의 입력을 받는다.

케라스에 있는 모든 순환 층과 마찬가지로 SimpleRNN은 두 가지 모드로 실행할 수 있다. 각 타임스텝의 출력을 모은 전체 시퀀스를 반환하거나 (출력 크기가 (batch_size, timesteps, output_features)인 3D 텐서), 입력 시퀀스에 대한 마지막 출력만 반환할 수 있다. (출력 크기가 (batch_size, output_features)인 2D 텐서) 이 모드는 객체를 생성할 때 return_sequences 매개변수로 선택할 수 있다.

```python
model.add(Embedding(10000, 32))
model.add(SimpleRNN(32, return_sequences=True)) # 마지막 타임스텝의 출력만 반환
model.add(SimpleRNN(32)) # 전체 타임스텝의 출력 반환
```

> 층의 이름은 클래스 이름에서 단어 사이에 언더바를 추가하고 소문자로 바꾸어 사용한다. 이름 뒤에 붙는 숫자는 클래스별로 1씩 증가된다. 별도의 이름을 주려면 매개변수로 name을 설정한다.

네트워크의 표현력을 증가시키기 위해 여러 개의 순환 층을 쌓는 것이 유용할 때가 있다. 이런 설정에서는 중간층들이 <b>전체 출력 시퀀스를 반환</b>하도록 설정해야 한다.

##### LSTM과 GRU 층 이해하기

케라스에는 LSTM과 GRU라는 다른 순환 layer도 존재. RNN은 이론적으로는 이전의 모든 타임스텝에 대한 정보를 유지해야하나 실제로는 학습할 수 없다는 문제가 있다. <b>기울기 소실 문제(vanishing gradient problem)</b> 때문인데, 이 문제를 해결하기 위해 고안도니 것이 LSTM과 GRU이다.

LSTM(Long Short-Term Memory)는 정보를 여러 타임스텝에 걸쳐 나르는 방법이 추가되었다.
![LSTMflow](https://user-images.githubusercontent.com/27988544/65310734-ee093100-dbc9-11e9-9e6d-590767ccd741.jpg)

위의 LSTM 구조를 sudo code로 표현하면 다음과 같다.

```python
output_t = activation(c_t) * activation(dot(input_t, Wo) + dot(state_t, Uo) + bo)

i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)
f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf)
k_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)

c_{t+1} = i_t * k_t + c_t * f_t
```

먼저 c_t와 f_t의 곱셈은 이동을 위한 데이터 흐름에서 관련이 적은 정보를 의도적으로 삭제한다고 볼 수 있다.
한편 i_t와 k_t는 현재에 대한 정보를 제공하고, 이동 트랙을 새로운 정보로 업데이트한다고 볼 수 있다.

이런 해석 때문에 f_t의 계산식을 삭제 게이트(forget gate), i_t의 계산식을 입력 게이트(input gate)라고 부른다. 하지만 결국 이런 해석은 큰 의미가 없다. 이 연산들이 실제로 하는 일은 연산에 관련된 가중치 행렬에 따라 결정되기 때문이다.

요약하면 <b>LSTM 셀의 구체적인 구조에 대해 이해할 필요가 없다. 과거 정보를 나중에 다시 주입해서 gradient vanishing 문제를 해결한다는 점이 중요하다.</b>

```python
from keras.layrers import LSTM

model = Sequential()
model.add(Embedding(max_features, 32))
model.add(LSTM(32))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['acc'])
history = model.fit(input_train, y_train,
                    epochs=10,
                    batch_size=128,
                    validation_split=0.2)
```

#### 6-3. 순환 신경망의 고급 사용법

1. 순환 드롭아웃 (recurrent dropout)

   ```python
   model.add(layers.GRU(32,
                        dropout=0.2,			# input에 적용
                        recurrent_dropout=0.2,	 # state에 적용
                        input_shape=(None, float_data.shape[-1])))
   ```

2. 스태킹 순환 층 (stacking recurrent layer)

   Overfitting은 없지만, 성능상 병목이 있다고 판단될 때에는 네트워크 용량을 늘린다. 네트워크의 용량을 늘리려면 일반적으로 층의 유닛 수를 늘리거나, 층을 추가한다.

   케라스에서 순환 층을 차례대로 쌓으려면 모든 중간층은 마지막 타임스텝 출력만 아니라 전체 시퀀스(3D 텐서)를 출력해야 함. return_sequences=True로 지정.

   ```python
   model = Sequential()
   model.add(layers.GRU(32,
                        dropout=0.1,
                        recurrent_dropout=0.5,
                        return_sequences=True,
                        input_shape=(None, float_data.shape[-1])))
   model.add(layers.GRU(64, activation='relu',
                        dropout=0.1,
                        recurrent_dropout=0.5))
   ```

3. 양뱡향 순환 층(bidirectional recurrent layer)

   같은 정보를 다른 방향으로 볼 수 있어 시간 순서대로 처리할 때 놓칠 수 있는 패턴을 찾을 수 있다.
   
   ```python
   model = Sequential()
   model.add(layers.Embedding(max_faetures, 32))
   model.add(layers.Bidirectional(layers.LSTM(32)))
   model.add(layers.Dense(1, activation='sigmoid'))
   
   model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
   history = model.fit(x_train, y_train,
                       epochs=10,
                       batch_size=128,
                       validation_split=0.2)
   ```

#### 6-4. 컨브넷을 사용한 시퀀스 처리

1D 컨브넷은 특정 시퀀스 처리 문제에서 유용하며, 계산 비용이 RNN보다 싸다. 1D 컨브넷은 보통 팽창된 커널(dilated kernel)과 함께 사용된다. 최근 오디오 생성과 기계 번역 분야에서 큰 성과를 내고 있으며, 텍스트 분류나 시계열 예측 같은 간단한 문제에서 RNN을 대신해서 빠르게 처리할 수 있다.

> 팽창 합성곱(dilated convolution)은 커널에 구멍을 추가해서 입력을 건너뛰면서 합성곱하는 것과 같다. 프랑스어로 '무겅이 난'이란 뜻의 아트루스에서 따와 아트루스 합성곱(atrous convolution)이라고도 부른다. 케라스에서는 Conv1D와 Conv2D의 dilation_rate 매개변수에서 팽창 비율을 지정할 수 있으며, 이미지 분할(image segmentation) 분야 등에 많이 사용된다.
>
> 구글 딥마인드가 <a href="https://arxiv.org/abs/1609.03499">WaveNet</a>에 적용해서 유명해짐.

1. 시퀀스 데이터를 위한 1D 합성곱 이해하기.

   이미지 텐서에서 2D 패치를 추출하고 모든 패치에 동일한 변환을 적용했던 것 처럼, 시퀀스에서 1D 패치(부분 시퀀스)를 추출하여 1D 합성곱을 한다. 이렇게 하면 시퀀스에 있는 지역 패턴을 인식할 수 있다. 동일한 변환이 시퀀스에 있는 모든 패치에 적용되기 때문에 특정 위치에서 학습한 패턴을 나중에 다른 위치에서 인식할 수 있다. 이는 1D 컨브넷에 (시간의 이동에 대한) 이동 불변성(translation invariant)을 제공한다. 따라서 문자 수준의 1D 컨브넷은 단어 형태학(word morphology)에 관해 학습할 수 있다.

   > <a href="https://arxiv.org/abs/1610.03017">Fully Character-Level Neural Machine Translation without Explicit Segmentation</a>

2. 시퀀스 데이터를 위한 1D 풀링

   이미지 텐서의 크기를 다운샘플링하기 위해 사용하는 2D 풀링 연산과 동일하게, 입력에서 1D 패치를 추출하고 최댓값 혹은 평균값을 출력한다. 마찬가지로 입력의 길이를 줄이기 위해 사용한다(서브샘플링(subsampling)).

3. 1D 컨브넷 구현

   케라스에서 Conv1D를 사용해서 구현한다. (samples, time, features) 크기의 3D 텐서를 입력받고 비슷한 형태의 3D 텐서를 반환한다. 이 때, 합성곱 윈도우는 시간 축의 1D 윈도우이다.

   ```python
   max_features = 10000
   max_len = 500
   
   (x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=max_features)
   
   x_train = sequence.pad_sequences(x_train, maxlen=max_len)
   x_test = sequence.pad_sequences(x_test, maxlen=max_len)
   
   model = Sequential()
   model.add(layers.Embedding(max_features, 128, input_length=max_len))
   model.add(layers.Conv1D(32, 7, activation='relu'))
   model.add(layers.MaxPooling1D(5))
   model.add(layers.Conv1D(32, 7, activation='relu'))
   model.add(layers.GlobalMaxPooling1D())
   model.add(layers.Dense(1))
   
   model.summary()
   model.compile(optimizer=RMSprop(lr=1e-4),
                 loss='binary_crossentropy',
                 metrics=['acc'])
   history = model.fit(x_train, y_train,
                       epochs=10,
                       batch_size=128,
                       validation_split=0.2)
   ```

   여기서 GlobalAveragePooling1D, GlobalMaxPooling1D 풀링은 (samples, timesteps, features) 크기의 텐서를 입력받고 (samples, features) 크기의 텐서를 출력한다. 즉 시간 축 전체에 풀링을 적용한다.

4. CNN과 RNN을 연결하여 긴 시퀀스를 처리하기

   1D 컨브넷이 입력 패치를 독립적으로 처리하기 때문에 RNN과 달리 타임스텝의 순서에 민감하지 않다. 따라서 1D 컨브넷의 속도와 경량함을 RNN의 순서 감지 능력과 결합하는 한 가지 전략은 1D 컨브넷을 RNN 이전에 전처리 단계로 사용하는 것이다. 수천 개의 스텝을 가진 시퀀스같이 RNN으로 처리하기 너무 긴 시퀀스를 다룰 때 좋음. 컨브넷이 긴 입력 시퀀스를 더 짧은 고수준 특성의 (다운샘플링된) 시퀀스로 변환하고, 이는 RNN 파트의 입력이 된다.

   <p align="center">긴 시퀀스 -> 1D CNN -> 짧은 시퀀스 -> RNN</p>

### &#128218; 7장. 딥러닝을 위한 고급 도구

케라스의 함수형 API를 사용해서 그래프 구조를 띤 모델을 만들거나 하나의 층을 다른 입력에 같이 사용하고, 케라스 모델을 파이썬 함수처럼 사용할 수 있다. 케라스 콜백과 브라우저 기반의 시각화 도구인 텐서보드는 모델 모니터링에 유용하다. 또한 배치 정규화, 잔차 연결, 하이퍼파라미터 최적화, 모델 앙상블을 포함한 사례 소개.

#### 7-1. Sequential 모델을 넘어서: 케라스의 함수형 API

일부 네트워크는 개별 입력이 여러개 필요하거나 출력이 여러개 필요하다. 층을 차례대로 쌓지 않고 층 사이를 연결하여 그래프처럼 만드는 네트워크도 있다. 최근에 개발된 많은 신경망 구조는 선형적이지 않은 네트워크 토폴로지(topology)가 필요하다. (대표적으로 <a href="https://arxiv.org/abs/1409.4842">Inception</a>, <a href="https://arxiv.org/abs/1512.03385">ResNet</a>)이러한 네트워크는 Sequential 모델을 사용해서 만들 수 없다. 그래서 새로운 방법인 <b>함수형 API</b>를 사용한다.

1. 함수형 API 소개

   함수처럼 층을 사용하여 텐서를 입력받고 출력한다.
   다음은 Sequential 모델과 함수형 API 모델 비교

   ```python
   from keras.models import Sequential, Model
   from keras import Input, layers
   
   seq_model = Sequential()
   seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))
   seq_model.add(layers.Dense(32, activation='relu'))
   seq_model.add(layers.Dense(10, activation='softmax'))
   
   input_tensor = Input(shape=(64,))
   x = layers.Dense(32, activation='relu')(input_tensor)
   x = layers.Dense(32, activation='relu')(x)
   output_tensor = layers.Dense(10, activation='softmax')(x)
   
   model = Model(input_tensor, output_tensor)
   # compile, fit, evaluate는 동일
   ```

2. 다중 입력 모델

   여러 텐서를 연결하는 방법은 layers.add, layers.concatenate, layers.average 등등..

   ```python
   from keras.models import Model
   from keras import layers
   from keras import Input
   
   text_vocabulary_size = 10000
   question_vocabulary_size = 10000
   answer_vocabulary_size = 500
   
   text_input = Input(shape=(None,), dtype='int32', name='text')
   embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)
   encoded_text = layers.LSTM(32)(embedded_text)
   
   question_input = Input(shape=(None,), dtype='int32', name='question')
   embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)
   encoded_question = layers.LSTM(16)(embedded_question)
   
   concatenated = layers.concatenate([encoded_text, encode_question], axis=-1)
   answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)
   
   model = Model([text_input, question_input], answer)
   model.compile(optimizer='rmsprop',
                 loss='categorical_crossentropy',
                 metrics=['acc'])
   model.fit([text, question], answer, epochs=10, batch_size=128)
   # 입력 이름을 지정했을 때는 딕셔너리 입력 사용 가능
   # model.fit({'text':text, 'question':question}, answer, epochs=10, batch_size=128)
   ```

3. 다중 출력 모델

   ```python
   model.compile(optimizer='rmsprop',
                 loss=['mse', 'categorical_crossentorpy', 'binary_crossentropy'])
   
   # 다중 입력 모델과 같이 이름을 지정했을 때는 딕셔너리 사용 가능
   model.compile(optimizer='rmsprop',
                 loss={'age': 'mse',
                       'income': 'categorical_crossentropy',
                      'gender': 'binary_crossentropy'})
   ```

   이렇게 계산된 손실값들은 전체 손실 하나로 더해지고 훈련과정을 통해 최소화된다. 이 때 손실 값의 크기가 불균형하면 모델이 개별 손실이 가장 큰 작업에 치우쳐 표현을 최적화하는 문제가 생긴다. 따라서 손실값이 최종 손실에 기여하는 수준을 조정해야하고, 특히 손실 값의 스케일이 다를 때 유용하다. 따라서 적절한 가중치 값을 각 손실 출력에 곱한뒤 더하는 방식으로 해결할 수 있다.

4. Inception 모델

   ![inception](https://user-images.githubusercontent.com/27988544/65399497-ea5af180-ddf7-11e9-9f49-8a43cc501c93.jpg)
   Inception V3에 사용되는 모듈
   {:.figure}

   ><b>Q. 1 x 1 합성곱의 목적</b>
   >
   >합성곱은 입력 텐서에서 타일 주변의 패치를 추출하고 각 패치에 동일한 연산을 수행한다. 이 경우는 추출된 패치가 하나의 타일로 이루어졌을 때다. 이 합성곱 연산은 모든 타일 벡터를 하나의 Dense 층에 통과시키는 것과 동일하다. 즉 입력 텐서의 채널 정보를 혼합한 특성을 계산한다. 공간 방향으로는 정보를 섞지 않는다(한 번에 하나의 타일만 처리하기 때문). 이런 1 x 1 합성곱(또는 점별 합성곱(pointwise convolution))은 입셉션 모듈의 특징이다. 채널 방향의 특성 학습과 공간 방향의 특성 학습을 분리하는데 도움을 준다. 채널이 공간 방향으로 상관관계가 크고 채널 간에는 독립적이라고 가정하면 납득할 수 있는 전략이다.

   

   ```python
   from keras import layers
   # 모든 가지는 stride(2)를 사용한다. 출력 크기를 동일하게 만들어 하나로 합치기 위함
   branch_a = layers.Conv2D(128, 1,
                            activation='relu', strides=2)(x)
   branch_b = layers.Conv2D(128, 1, activation='relu')(x)
   branch_c = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)
   
   branch_c = layers.AveragePooling2D(3, strides=2)(x)
   branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)
   
   branch_d = layers.Conv2D(128, 1, activation='relu')(x)
   branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)
   branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)
   output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)
   ```

   인셉션 V3 전체 구조는 keras.applications.inception_v3.InceptionV3에 있으며, ImageNet 데이터셋에서 사전 훈련된 가중치를 포함하고 있다. 이와 아주 비슷한 모델인 <a href="https://arxiv.org/abs/1610.02357">엑셉션(Xception)</a>도 케라스의 애플리케이션 모듈에 포함되어 있다.

5. 잔차 연결 (residual connection)

   대규모 딥러닝 모델에서 흔히 나타나는두 가지 문제인 그래디언트 소실과 표현 병목을 해결한 모델. 일반적으로 10개 층 이상을 가진 모델에 잔차 연결을 추가하면 도움이 된다.

   잔차 연결은 하위 층의 출력을 상위 층의 입력으로 사용한다. 즉, 순서대로 놓인 네트워크를 질러가는 연결이 존재한다. 다만 하위 층의 출력이 상위 층의 활성화 출력에 연결되는 것이 아니라 더해진다. 따라서 크기가 동일해야 한다. 만약 크기가 다르면 선형 변환을 사용해서 하위층의 활성화 출력을 목표 크기로 변환해야 한다. (ex. 활성 함수 없는 Dense 층, 합성곱의 특성 맵이라면 활성 함수가 없는 1 x 1 합성곱)

   ```python
   x = ...
   y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)
   y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)
   y = layers.Conv2D(128, 3, activation='relu', padding='smae')(y)
   
   y = layers.add([y, x]) # 원본 x를 출력 특성에 더함.
   ```

   > <b>1. 딥러닝의 표현 병목</b>
   >
   > Sequential 모델에서 층은 이전 층의 활성화 출력 정보만 사용한다. 어떤 층이 너무 작으면(특성이 너무 저차원이면) 이 활성화 출력에 얼마나 많은 정보를 채울 수 있느냐에 모델 성능이 좌우된다. 즉, 손실 정보를 채울 수 없게 되면 병목 현상이 일어나게 된다. 이를 해결할 수 있는 방법 중 하나가 잔차 연결.
   >
   > <b>2. 딥러닝의 그래디언트 소실 문제</b>
   >
   > 역전파는 출력 손실에서 얻은 피드백 신호를 하위 층에 전파한다. 만약 깊은 층을 통과하면 신호가 아주 작아지거나 사라져서 네트워크가 훈련되지 않을 수 있다. 이를 그래디언트 소실 문제라고 한다.
   >
   > 이 문제는 심층 신경망, 순환 신경망 모두에서 나타날 수 있다. 순환 신경망에서는 LSTM 층이 이 문제를 해결하기 위해 기억 보존 개념을 적용시키려는 시도를 한 것이고, 잔차 연결은 심층 신경망에서 문제를 해결하기 위한 기술이다.

#### 7.2 케라스 콜백과 텐서보드를 사용한 딥러닝 모델 검사와 모니터링

1. 콜백을 사용하여 모델의 훈련 과정 제어하기

   지금까지는 적절한 훈련 epoch를 알아내기 위해 첫 번째 실행에서 과대적합이 시작될 때까지 충분한 epoch로 훈련하고, 최적의 epoch 횟수로 처음부터 새로운 훈련을 했다. 더 좋은 처리 방법은 검증 손실이 더 이상 향상되지 않을 때 훈련을 멈추는 것이다. 이는 케라스의 콜백을 사용해서 구현할 수 있다.

   - 모델 체크포인트 저장: 훈련하는 동안 어떤 지점에서 모델의 현재 가중치를 저장
   - 조기 종료: 검증 손실이 더 이상 향상되지 않을 때 훈련을 중지.
   - 훈련하는 동안 하이퍼파라미터 값을 동적으로 조정: optimizer의 learning_rate 등
   - 훈련과 검증 지표를 로그에 기록하거나 모델이 학습한 표현이 업데이트될 때마다 시각화: 진행 표시줄 등

   <b>ModelCheckpoint와 EarlyStopping 콜백</b>

   EarlyStopping 콜백을 사용하면 정해진 epoch 동안 모니터링 지표가 향상되지 않을 때 훈련 중지 가능.

   ```python
   import keras
   
   # fit() 메소드의 callbacks 매개변수를 사용해서 콜백의 리스트를 모델로 전달.
   callbacks_list = [
       # 성능 향상이 멈추면 훈련 중지
       keras.callbacks.EarlyStopping(monitor='val_acc',     # 모델의 검증 정확도 모니터링
                                     patience=1),           # 1 epoch보다 더 길게 향상되지 않으면!
       # epoch마다 현재 가중치 저장
       # monitor와 save_best_only는 val_loss가 좋아지지 않으면 모델 파일을 덮어쓰지 않는다는 의미
       # 즉, 훈련 동안 가장 좋은 모델이 저장
       keras.callbacks.ModelCheckpoint(filepath='my_model.h5', 
                                       monitor='val_loss',
                                       save_best_only=True)
   ]
   
   model.compile(optimizer='rmsprop',
                 loss='binary_crossentropy',
                 metrics=['acc'])
   model.fit(x, y, 
             epochs=10, 
             batch_size=32, 
             callbacks=callbacks_list, 
             validation_date=(x_val, y_val))
   ```

   <b>ReduceLROnPlateau 콜백</b>

   이 콜백을 사용하면 검증 손실이 향상되지 않을 때 학습률을 작게 할 수 있다. 손실 곡선이 평탄할 때 학습률을 작게 하거나 크게 하면 훈련 도중 지역 최솟값에서 효과적으로 빠져나올 수 있다.

   ```python
   callbacks_list = [
       keras.callbacks.ReduceLROnPlateau(monitor='val_loss',
                                         factor=0.1,
                                         patience=10)
   ]
   
   model.fit(x, y,
             epochs=10,
             batch_size=32,
             callbacks=callbacks_list,
             validation_data=(x_val, y_val))
   ```

2. 텐서보드: 텐서플로우의 시각화 프레임워크

   ```python
   callbacks = [
       keras.callbacks.TensorBoard(log_dir='디렉토리이름',   # 로그 파일 기록 위치
                                   histogram_freq=1,        # 1epoch마다 활성 함수 출력 히스토그램 기록
                                   embeddings_freq=1)       # 1epoch마다 임베딩 데이터 기록
   ]
   history = model.fit(x_train, y_train,
                       epochs=20,
                       batch_size=128,
                       validation_split=0.2,
                       callbacks=callbacks)
   ```

   이 후 명령창에서 <b>tensorboard --logdir=디렉토리이름</b> 실행 -> 브라우저에서 <b>http://localhost:6006</b>

   > 추가적으로 모델 그래프만을 깔끔하게 그리기 위한 툴
   >
   > keras.utils.plot_model
   >
   > ```python
   > from keras.utils import plot_model
   > 
   > plot_model(model, show_shapes=True, to_file='model.png') # shape 까지
   > plot_model(model, to_file='model.png') # 층 구조만
   > ```

#### 7-3. 모델의 성능을 최대로 끌어올리기

1. 고급 구조 패턴

   - 배치 정규화

     <b>정규화(normalization)</b>는 샘플들을 균일하게 만드는 광범위한 방법. 이 방법은 모델이 학습하고 새로운 데이터에 잘 일반화되도록 한다. 책의 초반부에서는 모델에 데이터를 주입하기 전에 정규화를 했지만, 사실 네트워크에서 일어나는 모든 변환 후에도 정규화는 고려되어야 한다. Dense나 Conv2D 층에 들어가는 데이터의 평균이 0이고 분산이 1이더라도 출력되는 데이터가 동일한 분포를 가질 것이라 기대하기 어렵기 때문이다.

     <a href="https://arxiv.org/abs/1502.03167">배치 정규화</a>는 이러한 문제를 해결하기 위한 층의 한 종류이다. (케라스에서는 BatchNormalization 클래스 제공) 이는 훈련하는 동안 평균과 분산이 바뀌더라도 이에 적응해서 데이터를 정규화한다. 즉, 훈련 과정에 사용된 배치 데이터의 평균과 분산에 대한 지수 이동 평균(exponential moving average)을 내부에서 유지한다.

     > 더 자세하게 들어가면, 배치 정규화는 입력 배치의 평균과 표준 편차를 지수 이동 평균으로 계산하여 전체 데이터셋의 평균과 표준 편차를 대신한다. 이 값은 테스트 데이터에 배치 정규화가 적용될 때 사용된다. 지수 이동 평균은 3장에서 본 것처럼 
     >
     > $$v = v * momentum + v_new * (1 - momentum)$$
     >
     > 으로 계산된다. momentum이 클수록 이전 값(v)의 관성이 크며 새로운 값(v_new)이 미치는 영향이 적다. 케라스의 momentum 기본값은 0.99이다.

     배치 정규화는 잔차 연결과 매우 흡사하게 그래디언트의 전파를 도와준다. 더 자세하게 설명하면, 입력에 비해 활성 함수 출력이 너무 작거나 커지면 변화율이 급격히 작아져서 역전파되는 그래디언트도 매우 줄어들게 되지만, 배치 정규화는 입력과 출력의 분포를 유지하도록 도와주므로 그래디언트가 더 잘 전파된다.

     BatchNormalization 층은 일반적으로 합성곱이나 완전 연결 층 다음에 사용한다. BatchNormalization 클래스에는 정규화할 특성 축을 지정하는 axis 매개변수가 있다. 이 매개변수의 default는 -1이다. data_format을 "channels_last"로 해서 Dense, Conv1D, RNN, Conv2D 층을 사용할 때는 이상이 없다. 하지만 data_format을 "channels_first"로 사용하는 경우에는 특성 축이 1이다(0번째는 배치 차원). 이때는 axis=1로 변경해야 한다.

     > <a href="https://arxiv.org/abs/1702.03275">배치 재정규화 (batch renormalization)</a>
     >
     > 추가적인 비용없이 배치 정규화보다 발전된 내용.

   - 깊이별 분리 합성곱

     Conv2D를 대체하면서 더 가볍고 더빨라 모델의 성능을 높일 수 있는 층, <b>깊이별 분리 합성곱(depthwise separable convolution).</b> 케라스에서는 SeparableConv2D. 이 층은 입력 채널별로 따로 공간 방향의 합성곱을 수행한다. 그리고 1 x 1 합성곱을 통해 출력 채널을 합친다. 이는 공간 특성의 학습과 채널 방향 특성의 학습을 분리하는 효과를 낸다.

     ```python
     from keras.models import Sequential, Model
     from keras import layers
     
     height = 64
     width = 64
     channels = 3
     num_classes = 10
     
     model = Sequential()
     model.add(layers.SeparableConv2D(32, 3,
                                      activation='relu',
                                      input_shape=(height, width, channels, )))
     model.add(layers.SeparableConv2D(64, 3, activation='relu'))
     model.add(layers.MaxPooling2D(2))
     
     model.add(layers.SeparableConv2D(64, 3, activation='relu'))
     model.add(layers.SeparableConv2D(128, 3, activation='relu'))
     model.add(layers.MaxPooling2D(2))
     
     model.add(layers.SeparableConv2D(64, 3, activation='relu'))
     model.add(layers.SeparableConv2D(128, 3, activation='relu'))
     model.add(layers.GlobalAveragePooling2D())
     
     model.add(layers.Dense(32, activation='relu'))
     model.add(layers.Dense(num_classes, activation='softmax'))
     
     model.compile(optimizer='rmsprop', loss='categorical_crossentropy')
     ```

     